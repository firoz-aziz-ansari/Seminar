{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Triplet Loss Function.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rd4mNUU0kBR0","colab_type":"code","outputId":"a59a634f-a2c4-49bf-e038-c0717a6b2fb4","executionInfo":{"status":"ok","timestamp":1547507347849,"user_tz":-60,"elapsed":26375,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"-TkQeVZ_9d6q","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":90},"outputId":"57d99844-f570-4360-da7b-15fe0fae1631","executionInfo":{"status":"ok","timestamp":1547507748972,"user_tz":-60,"elapsed":13552,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-239f60b3-8990-465f-a485-6a4d192c990c\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-239f60b3-8990-465f-a485-6a4d192c990c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving one-shot-classification.zip to one-shot-classification.zip\n","User uploaded file \"one-shot-classification.zip\" with length 389068 bytes\n"],"name":"stdout"}]},{"metadata":{"id":"18gU-jJXDcVg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":588353,"output_embedded_package_id":"1JstCBlXRBdYoU-fQPniCaz835RwOnunk"},"outputId":"72c36949-ddb8-418b-fdc6-865a474dbcd7","executionInfo":{"status":"ok","timestamp":1547507760495,"user_tz":-60,"elapsed":9941,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["!unzip Omniglot.zip\n","!unzip one-shot-classification.zip"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"metadata":{"id":"wac06CtakSUp","colab_type":"text"},"cell_type":"markdown","source":["code inspired by : https://github.com/Chtchou/Fellow_omniglot/blob/master/Fellowship_ai_One_shot_Omniglot.ipynb"]},{"metadata":{"id":"mIwAIwiEkXlE","colab_type":"text"},"cell_type":"markdown","source":["# Triplet Loss Function"]},{"metadata":{"id":"z9kCt_KYnQ8p","colab_type":"text"},"cell_type":"markdown","source":["### Preprocessing dataset"]},{"metadata":{"id":"ynjhj1dZka_N","colab_type":"code","outputId":"ecb20284-9045-4f47-bea7-143df1045d48","executionInfo":{"status":"ok","timestamp":1547507931503,"user_tz":-60,"elapsed":410,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["import os\n","import glob\n","\n","import tensorflow as tf\n","import numpy as np\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, concatenate,AveragePooling2D, Lambda, Add\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from keras import regularizers\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from skimage.transform import resize\n","import h5py\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":14,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"metadata":{"id":"RB8KWGpQkbCq","colab_type":"code","colab":{}},"cell_type":"code","source":["PATH = \"/content/Omniglot/images_background\" #Training images path\n","\n","PATH_TEST = \"/content/Omniglot/images_evaluation\" #Validation and test images path"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KCnHHM0BkbFT","colab_type":"code","outputId":"8f5bc456-0793-4a4d-b3ae-d911eee24445","executionInfo":{"status":"ok","timestamp":1547507935747,"user_tz":-60,"elapsed":424,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"cell_type":"code","source":["alph_type = np.array(os.listdir(PATH)) #Give the different types of alphabet in our training data\n","print(f\"List of the different alphabets:\\n {alph_type}\")\n","print(f\"\\nNumber of different alphabets: {len(alph_type)}\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["List of the different alphabets:\n"," ['Tagalog' 'Korean' 'N_Ko' 'Anglo-Saxon_Futhorc' 'Latin'\n"," 'Ojibwe_(Canadian_Aboriginal_Syllabics)'\n"," 'Blackfoot_(Canadian_Aboriginal_Syllabics)' 'Arcadian'\n"," 'Syriac_(Estrangelo)' 'Balinese' 'Japanese_(katakana)' 'Sanskrit'\n"," 'Armenian' 'Asomtavruli_(Georgian)' 'Hebrew' 'Cyrillic' 'Gujarati'\n"," 'Early_Aramaic' 'Grantha' 'Mkhedruli_(Georgian)' 'Malay_(Jawi_-_Arabic)'\n"," 'Inuktitut_(Canadian_Aboriginal_Syllabics)' 'Bengali'\n"," 'Japanese_(hiragana)' 'Futurama' 'Alphabet_of_the_Magi' 'Greek' 'Braille'\n"," 'Burmese_(Myanmar)' 'Tifinagh']\n","\n","Number of different alphabets: 30\n"],"name":"stdout"}]},{"metadata":{"id":"_5j8C7qpUR8j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"outputId":"82c0147e-d2c2-4472-f563-296dcb76e213","executionInfo":{"status":"ok","timestamp":1547507937704,"user_tz":-60,"elapsed":396,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["alph_type_test = np.array(os.listdir(PATH_TEST)) #Give the different types of alphabet in our evaluation data\n","print(f\"List of the different alphabets:\\n {alph_type_test}\")\n","print(f\"\\nNumber of different alphabets: {len(alph_type_test)}\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["List of the different alphabets:\n"," ['Oriya' 'Malayalam' 'Gurmukhi' 'Atlantean' 'Ge_ez' 'Angelic' 'Tibetan'\n"," 'Sylheti' 'Manipuri' 'ULOG' 'Avesta' 'Keble' 'Atemayar_Qelisayer'\n"," 'Syriac_(Serto)' 'Glagolitic' 'Tengwar' 'Mongolian'\n"," 'Old_Church_Slavonic_(Cyrillic)' 'Kannada' 'Aurek-Besh']\n","\n","Number of different alphabets: 20\n"],"name":"stdout"}]},{"metadata":{"id":"tC1gl1uYkbIG","colab_type":"code","outputId":"19103e55-be7b-4518-c98d-d5a8a0f8e8a1","executionInfo":{"status":"ok","timestamp":1547507939556,"user_tz":-60,"elapsed":387,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"cell_type":"code","source":["#First shuffle the alphabets\n","np.random.shuffle(alph_type)\n","\n","alph_type_train = alph_type[:27]\n","alph_type_val = alph_type[27:]\n","\n","print(f\"List of the different alphabets in training set:\\n {alph_type_train}\")\n","print(f\"\\nNumber of different alphabets in training set: {len(alph_type_train)}\")\n","print(f\"\\nList of the different alphabets in validation set:\\n {alph_type_val}\")\n","print(f\"\\nNumber of different alphabets in validation set: {len(alph_type_val)}\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["List of the different alphabets in training set:\n"," ['Alphabet_of_the_Magi' 'Bengali' 'Tagalog' 'Early_Aramaic' 'Latin'\n"," 'Cyrillic' 'Futurama' 'Sanskrit' 'Arcadian' 'Mkhedruli_(Georgian)'\n"," 'Inuktitut_(Canadian_Aboriginal_Syllabics)' 'Anglo-Saxon_Futhorc'\n"," 'Japanese_(hiragana)' 'Malay_(Jawi_-_Arabic)' 'Balinese'\n"," 'Asomtavruli_(Georgian)' 'Greek' 'N_Ko' 'Braille' 'Gujarati'\n"," 'Blackfoot_(Canadian_Aboriginal_Syllabics)' 'Syriac_(Estrangelo)'\n"," 'Japanese_(katakana)' 'Tifinagh' 'Grantha' 'Korean'\n"," 'Ojibwe_(Canadian_Aboriginal_Syllabics)']\n","\n","Number of different alphabets in training set: 27\n","\n","List of the different alphabets in validation set:\n"," ['Hebrew' 'Burmese_(Myanmar)' 'Armenian']\n","\n","Number of different alphabets in validation set: 3\n"],"name":"stdout"}]},{"metadata":{"id":"_7SlMDqKn4Q_","colab_type":"code","outputId":"b74749d1-4e90-43a3-e577-8f5fdc6cdb10","executionInfo":{"status":"ok","timestamp":1547507944629,"user_tz":-60,"elapsed":360,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"cell_type":"code","source":["alph_num_char_train = {alphabet:len(os.listdir(f'{PATH}/{alphabet}')) for alphabet in alph_type_train}\n","num_of_char_train = alph_num_char_train.values()\n","print(f'\\nThe maximum number of different character for one alphabet is {max(num_of_char_train)}')\n","print(f'The minimum number of different character for one alphabet is {min(num_of_char_train)}')\n","total_char_train = sum(num_of_char_train)\n","print(f'The total number of different character is {total_char_train}')\n","\n","\n","alph_num_char_val = {alphabet:len(os.listdir(f'{PATH}/{alphabet}')) for alphabet in alph_type_val}\n","num_of_char_val = alph_num_char_val.values()\n","print(f'\\nThe maximum number of different character for one alphabet is {max(num_of_char_val)}')\n","print(f'The minimum number of different character for one alphabet is {min(num_of_char_val)}')\n","total_char_val = sum(num_of_char_val)\n","print(f'The total number of different character is {total_char_val}')\n","\n","\n","alph_num_char_test = {alphabet:len(os.listdir(f'{PATH_TEST}/{alphabet}')) for alphabet in alph_type_test}\n","num_of_char_test = alph_num_char_test.values()\n","print(f'\\nThe maximum number of different character for one alphabet is {max(num_of_char_test)}')\n","print(f'The minimum number of different character for one alphabet is {min(num_of_char_test)}')\n","total_char_test = sum(num_of_char_test)\n","print(f'The total number of different character is {total_char_test}')\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["\n","The maximum number of different character for one alphabet is 55\n","The minimum number of different character for one alphabet is 14\n","The total number of different character is 867\n","\n","The maximum number of different character for one alphabet is 41\n","The minimum number of different character for one alphabet is 22\n","The total number of different character is 97\n","\n","The maximum number of different character for one alphabet is 47\n","The minimum number of different character for one alphabet is 20\n","The total number of different character is 659\n"],"name":"stdout"}]},{"metadata":{"id":"kIBw_4E9oP4f","colab_type":"code","outputId":"bfee0df7-a90d-4ccb-c262-7850ed3d010a","executionInfo":{"status":"ok","timestamp":1547507947936,"user_tz":-60,"elapsed":379,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"cell_type":"code","source":["alph_num_char_ex_train = {}\n","for alphabet in alph_type_train:\n","    char_list_train = os.listdir(f'{PATH}/{alphabet}')\n","    for char in char_list_train:\n","        alph_num_char_ex_train[(alphabet,char)] = len(os.listdir(f'{PATH}/{alphabet}/{char}'))\n","num_of_example_train = alph_num_char_ex_train.values()\n","total_example_train = sum(num_of_example_train) \n","print(min(num_of_example_train),max(num_of_example_train))\n","print(f'The total number of different pictures is {total_example_train}')\n","\n","\n","alph_num_char_ex_val = {}\n","for alphabet in alph_type_val:\n","    char_list_val = os.listdir(f'{PATH}/{alphabet}')\n","    for char in char_list_val:\n","        alph_num_char_ex_val[(alphabet,char)] = len(os.listdir(f'{PATH}/{alphabet}/{char}'))\n","num_of_example_val = alph_num_char_ex_val.values()\n","total_example_val = sum(num_of_example_val) \n","print(min(num_of_example_val),max(num_of_example_val))\n","print(f'The total number of different pictures is {total_example_val}')\n","\n","alph_num_char_ex_test = {}\n","for alphabet in alph_type_test:\n","    char_list_test = os.listdir(f'{PATH_TEST}/{alphabet}')\n","    for char in char_list_test:\n","        alph_num_char_ex_test[(alphabet,char)] = len(os.listdir(f'{PATH_TEST}/{alphabet}/{char}'))\n","num_of_example_test = alph_num_char_ex_test.values()\n","total_example_test = sum(num_of_example_test) \n","print(min(num_of_example_test),max(num_of_example_test))\n","print(f'The total number of different pictures is {total_example_test}')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["20 20\n","The total number of different pictures is 17340\n","20 20\n","The total number of different pictures is 1940\n","20 20\n","The total number of different pictures is 13180\n"],"name":"stdout"}]},{"metadata":{"id":"hNKC_mDsm5rP","colab_type":"code","outputId":"0cf609c2-0309-4987-a0c4-9ce7cc315c47","executionInfo":{"status":"ok","timestamp":1547507950800,"user_tz":-60,"elapsed":414,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"cell_type":"code","source":["alph_type_test = np.array(os.listdir(PATH_TEST)) #Give the different types of alphabet in our evaluation data\n","print(f\"List of the different alphabets:\\n {alph_type_test}\")\n","print(f\"\\nNumber of different alphabets: {len(alph_type_test)}\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["List of the different alphabets:\n"," ['Oriya' 'Malayalam' 'Gurmukhi' 'Atlantean' 'Ge_ez' 'Angelic' 'Tibetan'\n"," 'Sylheti' 'Manipuri' 'ULOG' 'Avesta' 'Keble' 'Atemayar_Qelisayer'\n"," 'Syriac_(Serto)' 'Glagolitic' 'Tengwar' 'Mongolian'\n"," 'Old_Church_Slavonic_(Cyrillic)' 'Kannada' 'Aurek-Besh']\n","\n","Number of different alphabets: 20\n"],"name":"stdout"}]},{"metadata":{"id":"3ghzr1HsnUKf","colab_type":"code","outputId":"aa8e0a2d-d0be-467d-aac1-c55ce002b21c","executionInfo":{"status":"ok","timestamp":1547507952528,"user_tz":-60,"elapsed":389,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["total_example_train = sum(num_of_example_train)\n","Y_train = np.array([i//20+1 for i in range(total_example_train)])\n","Y_train=Y_train.reshape(*Y_train.shape,1)\n","Y_train.shape"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17340, 1)"]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"id":"7DMeJjiUpQR6","colab_type":"code","outputId":"662156f5-864d-49d4-d56d-57971a6e601d","executionInfo":{"status":"ok","timestamp":1547507954329,"user_tz":-60,"elapsed":409,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["Y_val = np.array([i//20+1 for i in range(total_example_val)])\n","Y_val=Y_val.reshape(*Y_val.shape,1)\n","Y_val.shape"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1940, 1)"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"id":"PFQQuTk1pXh_","colab_type":"code","outputId":"d9264d78-e5ec-46d8-df1b-c6f2ec5d5545","executionInfo":{"status":"ok","timestamp":1547507956099,"user_tz":-60,"elapsed":384,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["Y_test = np.array([i//20+1 for i in range(total_example_test)])\n","Y_test=Y_test.reshape(*Y_test.shape,1)\n","Y_test.shape"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13180, 1)"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"11XgY891pdAQ","colab_type":"code","colab":{}},"cell_type":"code","source":["trainPath = []\n","for alphabet in alph_type_train:\n","    trainPath += glob.glob(f\"{PATH}/{alphabet}/*/*.png\")\n","trainPath[0:5]\n","\n","valPath = []\n","for alphabet in alph_type_val:\n","    valPath += glob.glob(f\"{PATH}/{alphabet}/*/*.png\")\n","    \n","testPath = glob.glob(f\"{PATH_TEST}/*/*/*.png\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V1tMvq9Qpkb4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6a82e668-4c2a-4bbd-c33c-2ca3807415f4","executionInfo":{"status":"ok","timestamp":1547507991282,"user_tz":-60,"elapsed":25595,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["SZ=64 #imagesize\n","channel_sz = 1 #number of channel\n","\n","X_train = np.array([resize(mpimg.imread(i), (SZ,SZ), mode='edge') for i in trainPath])\n","X_train= X_train.reshape(*X_train.shape, channel_sz)\n","X_train.shape"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17340, 64, 64, 1)"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"pbyK7a87sSq-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7853397e-2376-45ec-f610-a8701688103e","executionInfo":{"status":"ok","timestamp":1547507996245,"user_tz":-60,"elapsed":3327,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["X_val = np.array([resize(mpimg.imread(i), (SZ,SZ), mode='edge') for i in valPath])\n","X_val= X_val.reshape(*X_val.shape, channel_sz)\n","X_val.shape"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1940, 64, 64, 1)"]},"metadata":{"tags":[]},"execution_count":28}]},{"metadata":{"id":"Dq2024yfsSws","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6c856f6c-6d3a-49b2-c098-14ae9b80b1f3","executionInfo":{"status":"ok","timestamp":1547508000385,"user_tz":-60,"elapsed":3154,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["X_test = np.array([mpimg.imread(i) for i in testPath])\n","X_test= X_test.reshape(*X_test.shape, channel_sz)\n","X_test.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13180, 105, 105, 1)"]},"metadata":{"tags":[]},"execution_count":29}]},{"metadata":{"id":"ECr3i62ZqJ2T","colab_type":"code","colab":{}},"cell_type":"code","source":["def triplet_loss(y_true, y_pred, alpha = 0.2):\n","    \"\"\"\n","    Implementation of the triplet loss\n","    \n","    Arguments:\n","    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n","    y_pred -- python list containing three objects:\n","            anchor -- the encodings for the anchor images, of shape (None, 64)\n","            positive -- the encodings for the positive images, of shape (None, 64)\n","            negative -- the encodings for the negative images, of shape (None, 64)\n","    \n","    Returns:\n","    loss -- real number, value of the loss\n","    \"\"\"\n","    \n","    anchor, positive, negative = y_pred[:,0:64], y_pred[:,64:128], y_pred[:,128:196]\n","    \n","    #Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n","    pos_dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1))\n","    #Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n","    neg_dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1))\n","    #Subtract the two previous distances and add alpha.\n","    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n","    # Count number of positive triplets (where triplet_loss > 0)\n","    valid_triplets = tf.to_float(tf.greater(basic_loss,0))\n","    num_positive_triplets = tf.reduce_sum(valid_triplets)\n","    #Take the maximum of basic_loss and 0.0. Sum over the training examples.\n","    loss = tf.reduce_mean(tf.maximum(basic_loss, 0))/ alpha * 100\n","    \n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mY_Zr8IaqNyO","colab_type":"code","colab":{}},"cell_type":"code","source":["def triplet_acc(y_true, y_pred, alpha = 0.2):\n","    \"\"\"\n","    Implementation of the triplet accuracy\n","    \n","    Arguments:\n","    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n","    y_pred -- python list containing three objects:\n","            anchor -- the encodings for the anchor images, of shape (None, 64)\n","            positive -- the encodings for the positive images, of shape (None, 64)\n","            negative -- the encodings for the negative images, of shape (None, 64)\n","    \n","    Returns:\n","    loss -- real number, value of the accuracy\n","    \"\"\"\n","    \n","    anchor, positive, negative = y_pred[:,0:64], y_pred[:,64:128], y_pred[:,128:196]\n","    \n","    #Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n","    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n","    #Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n","    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n","    #Subtract the two previous distances and add alpha.\n","    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n","    # Count number of positive triplets (where triplet_loss > 0)\n","    hard_triplets = tf.to_float(tf.greater(basic_loss,alpha))\n","    num_hard_triplets = tf.reduce_sum(hard_triplets)\n","    #Count number of triplets\n","    all_triplets = tf.reduce_sum(tf.to_float(tf.greater(basic_loss,-10**10)))\n","    \n","    #Accuracy\n","    acc = 1 - num_hard_triplets/all_triplets\n","    \n","    return acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PUQwwZ3nqQTu","colab_type":"code","colab":{}},"cell_type":"code","source":["def create_triplets(X, Y, num=1):\n","    \"\"\"\n","    Create a list of valid triplets for each valid (anchor, positive) couple\n","    \n","    Arguments:\n","    X -- array of images\n","    Y -- array of classes corresponding to each image\n","    num -- number of negative images for each valid anchor and positive images - must be positive\n","           if num = 0, all possible valid couples are created\n","            For example : for one valid (A,P) couple we can select 'num' random N images. \n","                          Thus 'num' triplets are created for this (A,P) couple\n","    \n","    Returns:\n","    (A,P,N) -- python tuple containing 3 arrays : \n","            A -- the array for the anchor images, of shape (None, 64)\n","            P -- the array for the positive images, of shape (None, 64)\n","            N -- the array for the negative images, of shape (None, 64)\n","    \"\"\"\n","\n","    Y = Y.reshape(Y.shape[0],)\n","    A = []\n","    P = []\n","    N = []\n","    \n","    #We loop over all possible valid (A,P)\n","    for i in range(X.shape[0]):  \n","        list_pos = X[Y==Y[i]]\n","        for j in list_pos:\n","            #We provide a number 'num' of triplets for each valid (A,P)\n","            if num >=1:\n","                for k in range(num):\n","                    rand_num = np.random.randint(X.shape[0])\n","                    if np.array_equal(X[i],j) == False:\n","                        A.append(X[i])\n","                        P.append(j)\n","                        while np.array_equal(Y[rand_num], Y[i]):\n","                            rand_num = np.random.randint(X.shape[0])\n","                        N.append(X[rand_num])\n","            if num == 0:\n","                for k in range(X.shape[0]):\n","                    if np.array_equal(X[i],j) == False:\n","                        if np.array_equal(Y[i],Y[k]) == False:\n","                            A.append(X[i])\n","                            P.append(j)\n","                            N.append(X[k])\n","    \n","    A = np.array(A)\n","    P = np.array(P)\n","    N = np.array(N)\n","    \n","    return (A, P, N)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WcOMCYrtqWXA","colab_type":"code","outputId":"62511ae7-34ab-474e-ebd9-1a1f8c7381f4","executionInfo":{"status":"ok","timestamp":1547508016795,"user_tz":-60,"elapsed":4364,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["triplets_list_val = create_triplets(X_val, Y_val, 1)\n","print([i.shape for i in triplets_list_val])"],"execution_count":33,"outputs":[{"output_type":"stream","text":["[(36860, 64, 64, 1), (36860, 64, 64, 1), (36860, 64, 64, 1)]\n"],"name":"stdout"}]},{"metadata":{"id":"w6yne_kdFfcC","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization\n","from keras.models import Model, Sequential\n","from keras.regularizers import l2\n","from keras import backend as K\n","from keras.losses import binary_crossentropy\n","import numpy as np\n","import os\n","import pickle\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","\n","def EmbModel(input_shape, l2):\n","    regul  = regularizers.l2(l2)\n","    kwargs = {'padding':'same', 'kernel_regularizer':regul,'kernel_initializer':'he_normal'}\n","\n","    inp = Input(input_shape) # 64x64x1\n","    x   = Conv2D(32, (3,3), strides=1, **kwargs)(inp) #32x32x64\n","    x   = BatchNormalization()(x)\n","    x   = Activation('relu')(x)\n","    \n","    #Stage 0 / resblock 0\n","    y   = Conv2D(32, (1,1), strides=1, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(32, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(64, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Conv2D(64, (1,1), strides=1, **kwargs) (x)\n","    x   = Add()([x,y])\n","    \n","    #Stage 0 / resblock 1\n","    x   = BatchNormalization()(x)\n","    x   = Activation('relu')(x)\n","    y   = Conv2D(32, (1,1), strides=1, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(32, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(64, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Add()([x,y])\n","    \n","    #Stage 1 / resblock 0\n","    y   = Conv2D(64, (1,1), strides=2, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(64, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(128, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Conv2D(128, (1,1), strides=2, **kwargs) (x)\n","    x   = Add()([x,y])\n","    \n","    #Stage 1 / resblock 1\n","    x   = BatchNormalization()(x)\n","    x   = Activation('relu')(x)\n","    y   = Conv2D(64, (1,1), strides=1, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(64, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(128, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Add()([x,y])\n","    \n","    #Stage 2 / resblock 0\n","    y   = Conv2D(128, (1,1), strides=2, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(128, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(256, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Conv2D(256, (1,1), strides=2, **kwargs) (x)\n","    x   = Add()([x,y])\n","    \n","    #Stage 2 / resblock 1\n","    x   = BatchNormalization()(x)\n","    x   = Activation('relu')(x)\n","    y   = Conv2D(128, (1,1), strides=1, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(128, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(256, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Add()([x,y])\n","    \n","    #Stage 3 / resblock 0\n","    y   = Conv2D(256, (1,1), strides=2, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(256, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(512, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Conv2D(512, (1,1), strides=2, **kwargs) (x)\n","    x   = Add()([x,y])\n","    \n","    #Stage 2 / resblock 1\n","    x   = BatchNormalization()(x)\n","    x   = Activation('relu')(x)\n","    y   = Conv2D(256, (1,1), strides=1, **kwargs)(x)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(256, (3,3), strides=1, **kwargs)(y)\n","    \n","    y   = BatchNormalization()(y)\n","    y   = Activation('relu')(y)\n","    y   = Conv2D(512, (1,1), strides=1, **kwargs)(y)\n","    \n","    x   = Add()([x,y])\n","    \n","    #Final\n","    x   = BatchNormalization()(x)\n","    x   = Activation('relu')(x)\n","    x   = AveragePooling2D(pool_size=8)(x)\n","    x   = Flatten()(x)\n","    x = Dense (64, activation ='tanh',kernel_initializer='he_normal') (x)\n","\n","    \n","    ##Create model\n","    model = Model(inputs = inp, outputs = x, name='EmbModel')\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6C-DYGZ9-sCg","colab_type":"code","colab":{}},"cell_type":"code","source":["#We define our global model\n","def global_model(size, channel_size=1, l2=1e-4):\n","    input_size = (size, size, channel_sz)                     \n","\n","    A = Input(input_size)\n","    P = Input(input_size)\n","    N = Input(input_size)\n","\n","    emb_model= EmbModel(input_size, l2)\n","\n","    out_A = emb_model(A)\n","    out_P = emb_model(P)\n","    out_N = emb_model(N)\n","\n","    y_pred = concatenate([out_A, out_P, out_N], axis =-1)\n","\n","    full_model = Model(inputs = [A, P, N], outputs = y_pred)\n","    \n","    return full_model, emb_model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9v8pWrVP-vyT","colab_type":"code","colab":{}},"cell_type":"code","source":["classification_model, emb_model = global_model(SZ,channel_sz, l2=1e-3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"02jHrgGD-wgN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3478},"outputId":"73ce6236-0f6f-4d78-aacf-75dc1a2cc4f3","executionInfo":{"status":"ok","timestamp":1547508051450,"user_tz":-60,"elapsed":374,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["classification_model.summary()\n","emb_model.summary()"],"execution_count":37,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 64, 64, 1)    0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 64, 64, 1)    0                                            \n","__________________________________________________________________________________________________\n","EmbModel (Model)                (None, 64)           2401728     input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 192)          0           EmbModel[1][0]                   \n","                                                                 EmbModel[2][0]                   \n","                                                                 EmbModel[3][0]                   \n","==================================================================================================\n","Total params: 2,401,728\n","Trainable params: 2,394,880\n","Non-trainable params: 6,848\n","__________________________________________________________________________________________________\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 64, 64, 1)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 64, 64, 32)   320         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 64, 64, 32)   128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 64, 64, 32)   1056        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 64, 64, 32)   128         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 64, 64, 32)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 64, 64, 32)   9248        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 64, 64, 32)   128         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 64, 64, 32)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 64, 64, 64)   2112        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 64, 64, 64)   2112        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         add_1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 64, 64, 32)   2080        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 64, 64, 32)   128         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 64, 64, 32)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 64, 64, 32)   9248        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 64, 64, 32)   128         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 64, 64, 32)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 64, 64, 64)   2112        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 64, 64, 64)   0           activation_4[0][0]               \n","                                                                 conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 64)   4160        add_2[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 64)   36928       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 128)  8320        add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 128)  8320        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 32, 32, 128)  0           conv2d_12[0][0]                  \n","                                                                 conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_3[0][0]                      \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 32, 32, 64)   8256        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 64)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 32, 128)  8320        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 32, 32, 128)  0           activation_9[0][0]               \n","                                                                 conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 16, 16, 128)  16512       add_4[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 128)  147584      activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 256)  33024       add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 256)  33024       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_19[0][0]                  \n","                                                                 conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 16, 16, 256)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 128)  32896       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 16, 16, 128)  147584      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 16, 16, 256)  33024       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 16, 16, 256)  0           activation_14[0][0]              \n","                                                                 conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 8, 8, 256)    65792       add_6[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 8, 8, 256)    1024        conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 8, 8, 256)    0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 8, 8, 256)    590080      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 8, 8, 256)    1024        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 8, 8, 256)    0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 8, 8, 512)    131584      add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 8, 8, 512)    131584      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 8, 8, 512)    0           conv2d_26[0][0]                  \n","                                                                 conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 8, 8, 512)    2048        add_7[0][0]                      \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 8, 8, 512)    0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 8, 8, 256)    131328      activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 8, 8, 256)    1024        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 8, 8, 256)    0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 8, 8, 256)    590080      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 8, 8, 512)    131584      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 8, 8, 512)    0           activation_19[0][0]              \n","                                                                 conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 8, 8, 512)    2048        add_8[0][0]                      \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 8, 8, 512)    0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_22[0][0]              \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 64)           32832       flatten_1[0][0]                  \n","==================================================================================================\n","Total params: 2,401,728\n","Trainable params: 2,394,880\n","Non-trainable params: 6,848\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"Ag9RwyPQHxRk","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.image import random_rotation, random_shift, random_shear, random_zoom\n","\n","def augmentation_pipeline(img_arr):\n","    img_arr = random_rotation(img_arr, 30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n","    img_arr = random_shear(img_arr, intensity=0.2, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n","    img_arr = random_zoom(img_arr, zoom_range=(0.85, 1.15), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n","    img_arr = random_shift(img_arr, wrg=0.15, hrg=0.15,fill_mode='nearest')\n","    return img_arr\n","\n","def batch_generator(X,Y, bs=32,hardmode = False):\n","    \"\"\"\n","    Create a mini-batch generator\n","    \n","    Arguments:\n","    X -- array of images\n","    Y -- array of classes corresponding to each image\n","    bs -- size of the minibatch\n","\n","    \n","    Returns:\n","    [A_batch, P_batch, N_batch], y_dummie) -- a mini-batch of size bs\n","    \"\"\"\n","    Y = Y.reshape(Y.shape[0],)\n","    while True:\n","        #0. Initialize Anchor,Postive, Negative\n","        A_batch = []\n","        P_batch = []\n","        N_batch = []\n","        for i in range(bs) :\n","            #1.Choose a random Anchor Image\n","            rand_A_num = np.random.randint(X.shape[0])    \n","\n","            #2.Choose a random Positive Image\n","            list_pos = X[Y==Y[rand_A_num]]                            #List of positive images\n","            rand_P_num = np.random.randint(len(list_pos))\n","            while np.array_equal(X[rand_A_num],list_pos[rand_P_num]):\n","                rand_P_num = np.random.randint(len(list_pos))\n","                \n","\n","            #3.Choose a random Negative Image\n","            rand_N_num = np.random.randint(X.shape[0])\n","            while np.array_equal(Y[rand_N_num], Y[rand_A_num]):\n","                rand_A_num = np.random.randint(X.shape[0])\n","                \n","            A_augment = augmentation_pipeline(X[rand_A_num])\n","            P_augment = augmentation_pipeline(list_pos[rand_P_num])\n","            N_augment = augmentation_pipeline(X[rand_N_num])\n","                    \n","            A_batch.append(A_augment)\n","            P_batch.append(P_augment)\n","            N_batch.append(N_augment)\n","            \n","        A_batch = np.array(A_batch)\n","        P_batch = np.array(P_batch)\n","        N_batch = np.array(N_batch)\n","        \n","        y_dummie = np.zeros((len(A_batch),))\n","        \n","        yield ([A_batch, P_batch, N_batch], y_dummie)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qeku0uzbH60O","colab_type":"text"},"cell_type":"markdown","source":["### Training the model"]},{"metadata":{"id":"CFjjg6LcH8uE","colab_type":"code","outputId":"f0b03f3b-8d17-4f5a-83c1-314d9c74ec16","executionInfo":{"status":"error","timestamp":1547483228019,"user_tz":-60,"elapsed":24592,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}},"colab":{"base_uri":"https://localhost:8080/","height":1630}},"cell_type":"code","source":["#Full network 1/32 - Embeddings 64 - Maxout\n","A_val, P_val, N_val = triplets_list_val\n","zeros_vect_val = np.zeros(A_val[:,1,1].shape) \n","\n","\n","batch_sz = 32\n","\n","model_name = '/content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5'\n","print(model_name)\n","    \n","#We create a checkpoint to save the best model and add an early stopping\n","checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","early_stop = EarlyStopping(monitor='val_loss', patience =10, verbose=1, mode='min')\n","lr_annealing = ReduceLROnPlateau(monitor='val_loss', patience = 2, epsilon=0.01, factor = 0.25, min_lr = 1e-7, verbose = 1, mode='min' )\n","callbacks_list = [checkpoint, early_stop, lr_annealing]\n","    \n","\n","#We compile our model with the custom made triplet_loss\n","classification_model.compile(optimizer = 'adam', loss = triplet_loss, metrics =[triplet_acc])\n","    \n","classification_model.fit_generator(batch_generator(X_train, Y_train, batch_sz, hardmode=False), \n","                                   steps_per_epoch = 800,\n","                                   epochs = 200,\n","                                   verbose = 2,\n","                                   validation_data = ([A_val, P_val, N_val], zeros_vect_val),\n","                                   callbacks = callbacks_list,)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/200\n"," - 470s - loss: 35.2996 - triplet_acc: 0.9014 - val_loss: 31.6165 - val_triplet_acc: 0.9143\n","\n","Epoch 00001: val_loss improved from inf to 31.61652, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 2/200\n"," - 446s - loss: 23.4048 - triplet_acc: 0.9491 - val_loss: 29.9092 - val_triplet_acc: 0.9237\n","\n","Epoch 00002: val_loss improved from 31.61652 to 29.90925, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 3/200\n"," - 444s - loss: 19.4531 - triplet_acc: 0.9639 - val_loss: 22.1446 - val_triplet_acc: 0.9531\n","\n","Epoch 00003: val_loss improved from 29.90925 to 22.14458, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 4/200\n"," - 444s - loss: 18.1805 - triplet_acc: 0.9670 - val_loss: 22.0729 - val_triplet_acc: 0.9524\n","\n","Epoch 00004: val_loss improved from 22.14458 to 22.07288, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 5/200\n"," - 441s - loss: 17.0897 - triplet_acc: 0.9696 - val_loss: 20.4436 - val_triplet_acc: 0.9588\n","\n","Epoch 00005: val_loss improved from 22.07288 to 20.44360, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 6/200\n"," - 442s - loss: 15.9235 - triplet_acc: 0.9725 - val_loss: 24.1365 - val_triplet_acc: 0.9408\n","\n","Epoch 00006: val_loss did not improve from 20.44360\n","Epoch 7/200\n"," - 441s - loss: 14.7021 - triplet_acc: 0.9759 - val_loss: 18.9708 - val_triplet_acc: 0.9611\n","\n","Epoch 00007: val_loss improved from 20.44360 to 18.97080, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 8/200\n"," - 441s - loss: 14.1056 - triplet_acc: 0.9761 - val_loss: 16.9846 - val_triplet_acc: 0.9652\n","\n","Epoch 00008: val_loss improved from 18.97080 to 16.98462, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 9/200\n"," - 440s - loss: 12.9949 - triplet_acc: 0.9796 - val_loss: 18.6560 - val_triplet_acc: 0.9563\n","\n","Epoch 00009: val_loss did not improve from 16.98462\n","Epoch 10/200\n"," - 440s - loss: 12.6120 - triplet_acc: 0.9789 - val_loss: 18.8153 - val_triplet_acc: 0.9563\n","\n","Epoch 00010: val_loss did not improve from 16.98462\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 11/200\n"," - 441s - loss: 9.8731 - triplet_acc: 0.9881 - val_loss: 11.0409 - val_triplet_acc: 0.9833\n","\n","Epoch 00011: val_loss improved from 16.98462 to 11.04089, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 12/200\n"," - 441s - loss: 9.2434 - triplet_acc: 0.9891 - val_loss: 10.4917 - val_triplet_acc: 0.9849\n","\n","Epoch 00012: val_loss improved from 11.04089 to 10.49172, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 13/200\n"," - 442s - loss: 8.7964 - triplet_acc: 0.9895 - val_loss: 10.8686 - val_triplet_acc: 0.9823\n","\n","Epoch 00013: val_loss did not improve from 10.49172\n","Epoch 14/200\n"," - 440s - loss: 8.1017 - triplet_acc: 0.9905 - val_loss: 10.5473 - val_triplet_acc: 0.9817\n","\n","Epoch 00014: val_loss did not improve from 10.49172\n","\n","Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","Epoch 15/200\n"," - 441s - loss: 7.7417 - triplet_acc: 0.9914 - val_loss: 9.0461 - val_triplet_acc: 0.9871\n","\n","Epoch 00015: val_loss improved from 10.49172 to 9.04606, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 16/200\n"," - 442s - loss: 7.4801 - triplet_acc: 0.9917 - val_loss: 8.7424 - val_triplet_acc: 0.9876\n","\n","Epoch 00016: val_loss improved from 9.04606 to 8.74238, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 17/200\n"," - 441s - loss: 7.2436 - triplet_acc: 0.9921 - val_loss: 9.0265 - val_triplet_acc: 0.9868\n","\n","Epoch 00017: val_loss did not improve from 8.74238\n","Epoch 18/200\n"," - 442s - loss: 6.9952 - triplet_acc: 0.9929 - val_loss: 8.5425 - val_triplet_acc: 0.9871\n","\n","Epoch 00018: val_loss improved from 8.74238 to 8.54251, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 19/200\n"," - 441s - loss: 6.7858 - triplet_acc: 0.9938 - val_loss: 8.5246 - val_triplet_acc: 0.9877\n","\n","Epoch 00019: val_loss improved from 8.54251 to 8.52458, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 20/200\n"," - 442s - loss: 6.9879 - triplet_acc: 0.9920 - val_loss: 8.9136 - val_triplet_acc: 0.9863\n","\n","Epoch 00020: val_loss did not improve from 8.52458\n","Epoch 21/200\n"," - 443s - loss: 6.8694 - triplet_acc: 0.9928 - val_loss: 8.2082 - val_triplet_acc: 0.9880\n","\n","Epoch 00021: val_loss improved from 8.52458 to 8.20820, saving model to /content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5\n","Epoch 22/200\n"," - 441s - loss: 6.5563 - triplet_acc: 0.9934 - val_loss: 8.2352 - val_triplet_acc: 0.9882\n","\n","Epoch 00022: val_loss did not improve from 8.20820\n","Epoch 23/200\n"],"name":"stdout"}]},{"metadata":{"id":"OGHc7heHydWk","colab_type":"text"},"cell_type":"markdown","source":["### Testing the model"]},{"metadata":{"id":"Zgckhes7ybiD","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import load_model\n","classification_model = load_model('/content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5')\n","global_loss=1e9\n","A_val, P_val, N_val = triplets_list_val\n","zeros_vect_val = np.zeros(A_val[:,1,1].shape) \n","\n","for weights in ['/content/gdrive/My Drive/Colab Notebooks/Saved Models/Triplet.h5']:\n","    classification_model.load_weights(weights)\n","    loss, acc = classification_model.evaluate([A_val, P_val, N_val], zeros_vect_val, batch_size = 32, verbose = 0)\n","    print(weights, loss, acc)\n","    if (loss < global_loss):\n","        model_name = weights\n","        global_loss = loss\n","        \n","classification_model.load_weights(model_name)\n","model_name, global_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"utNupIw_0M8a","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import copy\n","from scipy.ndimage import imread\n","from scipy.spatial.distance import cdist\n","\n","# Parameters\n","nrun = 20 # number of classification runs\n","fname_label = 'class_labels.txt' # where class labels are stored for each run\n","\n","def classification_run(main_folder,folder,f_load,f_cost,ftype='cost'):\n","\t# Compute error rate for one run of one-shot classification\n","\t#\n","\t# Input\n","\t#  folder : contains images for a run of one-shot classification\n","\t#  f_load : itemA = f_load('file.png') should read in the image file and process it\n","\t#  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n","\t#  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n","\t#\n","\t# Output\n","\t#  perror : percent errors (0 to 100% error)\n","\t# \n","\tassert ((ftype=='cost') | (ftype=='score'))\n","\n","\t# get file names\n","\twith open(main_folder+'/'+folder+'/'+fname_label) as f:\n","\t\tcontent = f.read().splitlines()\n","\tpairs = [line.split() for line in content]\n","\ttest_files  = [pair[0] for pair in pairs]\n","\ttrain_files = [pair[1] for pair in pairs]\n","\tanswers_files = copy.copy(train_files)\n","\ttest_files.sort()\n","\ttrain_files.sort()\t\n","\tntrain = len(train_files)\n","\tntest = len(test_files)\n","\n","\t# load the images (and, if needed, extract features)\n","\ttrain_items = [f_load(main_folder+'/'+f) for f in train_files]\n","\ttest_items  = [f_load(main_folder+'/'+f) for f in test_files ]\n","\n","\t# compute cost matrix\n","\tcostM = np.zeros((ntest,ntrain),float)\n","\tfor i in range(ntest):\n","\t\tfor c in range(ntrain):\n","\t\t\tcostM[i,c] = f_cost(test_items[i],train_items[c])\n","\tif ftype == 'cost':\n","\t\tYHAT = np.argmin(costM,axis=1)\n","\telif ftype == 'score':\n","\t\tYHAT = np.argmax(costM,axis=1)\n","\telse:\n","\t\tassert False\n","\n","\t# compute the error rate\n","\tcorrect = 0.0\n","\tfor i in range(ntest):\n","\t\tif train_files[YHAT[i]] == answers_files[i]:\n","\t\t\tcorrect += 1.0\n","\tpcorrect = 100 * correct / ntest\n","\tperror = 100 - pcorrect\n","\treturn perror\n","\n","def ModHausdorffDistance(itemA,itemB):\n","\t# Modified Hausdorff Distance\n","\t#\n","\t# Input\n","\t#  itemA : [n x 2] coordinates of \"inked\" pixels\n","\t#  itemB : [m x 2] coordinates of \"inked\" pixels\n","\t#\n","\t#  M.-P. Dubuisson, A. K. Jain (1994). A modified hausdorff distance for object matching.\n","\t#  International Conference on Pattern Recognition, pp. 566-568.\n","\t#\n","\tD = cdist(itemA,itemB)\n","\tmindist_A = D.min(axis=1)\n","\tmindist_B = D.min(axis=0)\n","\tmean_A = np.mean(mindist_A)\n","\tmean_B = np.mean(mindist_B)\n","\treturn max(mean_A,mean_B)\n","\n","def LoadImgAsPoints(fn):\n","\t# Load image file and return coordinates of 'inked' pixels in the binary image\n","\t# \n","\t# Output:\n","\t#  D : [n x 2] rows are coordinates\n","\tI = imread(fn,flatten=True)\n","\tI = np.array(I,dtype=bool)\n","\tI = np.logical_not(I)\n","\t(row,col) = I.nonzero()\n","\tD = np.array([row,col])\n","\tD = np.transpose(D)\n","\tD = D.astype(float)\n","\tn = D.shape[0]\n","\tmean = np.mean(D,axis=0)\n","\tfor i in range(n):\n","\t\tD[i,:] = D[i,:] - mean\n","\treturn D\n","\n","def CNNDistance(itemA, itemB):\n","    \"\"\"\n","    Compute the euclidean distance between the embeddings of the two images. \n","    The embeddings have been calculated by using the emb_model.\n","    \n","    Arguments:\n","    itemA -- array of images\n","    itemB -- array of images\n","    \n","    Returns:\n","    dist - euclidean distance\n","    \"\"\"\n","    \n","    itemA = itemA.reshape(1, itemA.shape[0], itemA.shape[1], 1)\n","    itemB = itemB.reshape(1, itemB.shape[0], itemB.shape[1], 1)\n","    itemA_emb = emb_model.predict_on_batch(itemA)\n","    itemB_emb = emb_model.predict_on_batch(itemB)\n","    dist = np.linalg.norm(itemA_emb - itemB_emb) #2-norm by default\n","    return dist\n","\n","\n","def LoadImgAsArray(fn):\n","    \"\"\"\n","    Load an image file, resize it and return an array\n","    \n","    Arguments:\n","    fn -- an image\n","    \n","    Returns:\n","    image -- an array of image \n","    \"\"\"\n","    picture = mpimg.imread(fn)\n","    image = resize(picture, (SZ,SZ), mode='edge')\n","    return image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pQ6BAS_G16t5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":437},"outputId":"77c006fe-ec41-4f13-fb48-e3f10fac7267","executionInfo":{"status":"ok","timestamp":1547508589806,"user_tz":-60,"elapsed":144102,"user":{"displayName":"Firoz Ansari","photoUrl":"https://lh3.googleusercontent.com/-FGTjg3groCo/AAAAAAAAAAI/AAAAAAAAAAs/aRZsuYekEKE/s64/photo.jpg","userId":"02762834003732646964"}}},"cell_type":"code","source":["#tanh32-4\n","print ('One-shot classification with Modified Hausdorff Distance versus embeddings triplet loss Distance')\n","perror = np.zeros(nrun)\n","perror_cnn = np.zeros(nrun)\n","for r in range(1,nrun+1):\n","\trs = str(r)\n","\tif len(rs) == 1:\n","\t\trs = '0' + rs\t\t\n","\tperror[r-1] = classification_run('one-shot-classification','/run'+rs, LoadImgAsPoints, ModHausdorffDistance, 'cost')\n","\tperror_cnn[r-1] = classification_run('one-shot-classification','run'+rs, LoadImgAsArray, CNNDistance, 'cost')\n","\tprint (\" run \" + str(r) + \" ModHausdorffDistance\" + \"(error \" + str(\tperror[r-1] ) + \"%)\"+ \"  -  Embeddings_triplet_loss_Distance\" + \" (error \" + str(\tperror_cnn[r-1] ) + \"%)\")\t\t\n","total = np.mean(perror)\n","total_cnn = np.mean(perror_cnn)\n","print (\" average error ModHausdorffDistance \" + str(total) + \"%\" + \"  average error Embeddings_triplet_loss_Distance \" + str(total_cnn) + \"%\")"],"execution_count":45,"outputs":[{"output_type":"stream","text":["One-shot classification with Modified Hausdorff Distance versus embeddings triplet loss Distance\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0.\n","Use ``matplotlib.pyplot.imread`` instead.\n"],"name":"stderr"},{"output_type":"stream","text":[" run 1 ModHausdorffDistance(error 45.0%)  -  Embeddings_triplet_loss_Distance (error 0.0%)\n"," run 2 ModHausdorffDistance(error 35.0%)  -  Embeddings_triplet_loss_Distance (error 15.0%)\n"," run 3 ModHausdorffDistance(error 40.0%)  -  Embeddings_triplet_loss_Distance (error 5.0%)\n"," run 4 ModHausdorffDistance(error 25.0%)  -  Embeddings_triplet_loss_Distance (error 10.0%)\n"," run 5 ModHausdorffDistance(error 30.0%)  -  Embeddings_triplet_loss_Distance (error 10.0%)\n"," run 6 ModHausdorffDistance(error 15.0%)  -  Embeddings_triplet_loss_Distance (error 0.0%)\n"," run 7 ModHausdorffDistance(error 60.0%)  -  Embeddings_triplet_loss_Distance (error 0.0%)\n"," run 8 ModHausdorffDistance(error 35.0%)  -  Embeddings_triplet_loss_Distance (error 20.0%)\n"," run 9 ModHausdorffDistance(error 40.0%)  -  Embeddings_triplet_loss_Distance (error 10.0%)\n"," run 10 ModHausdorffDistance(error 55.0%)  -  Embeddings_triplet_loss_Distance (error 25.0%)\n"," run 11 ModHausdorffDistance(error 15.0%)  -  Embeddings_triplet_loss_Distance (error 0.0%)\n"," run 12 ModHausdorffDistance(error 70.0%)  -  Embeddings_triplet_loss_Distance (error 5.0%)\n"," run 13 ModHausdorffDistance(error 65.0%)  -  Embeddings_triplet_loss_Distance (error 20.0%)\n"," run 14 ModHausdorffDistance(error 35.0%)  -  Embeddings_triplet_loss_Distance (error 20.0%)\n"," run 15 ModHausdorffDistance(error 15.0%)  -  Embeddings_triplet_loss_Distance (error 10.0%)\n"," run 16 ModHausdorffDistance(error 25.0%)  -  Embeddings_triplet_loss_Distance (error 5.0%)\n"," run 17 ModHausdorffDistance(error 30.0%)  -  Embeddings_triplet_loss_Distance (error 20.0%)\n"," run 18 ModHausdorffDistance(error 40.0%)  -  Embeddings_triplet_loss_Distance (error 15.0%)\n"," run 19 ModHausdorffDistance(error 70.0%)  -  Embeddings_triplet_loss_Distance (error 20.0%)\n"," run 20 ModHausdorffDistance(error 30.0%)  -  Embeddings_triplet_loss_Distance (error 10.0%)\n"," average error ModHausdorffDistance 38.75%  average error Embeddings_triplet_loss_Distance 11.0%\n"],"name":"stdout"}]}]}